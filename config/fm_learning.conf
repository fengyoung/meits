# activation function type of output layers
# the type can be set as 'linear' 'tanh', 'sigmoid', 'relu', 'softmax' or 'none'
Activation = sigmoid

# K val of FM, which indicates the size of factorization vector
FM_K = 40

# Regularization type
# L1, L2 or none
Regula = L1

# Mini-Batch
# 0 for batch-GD, 1 for SGD, greater than 1 for mini-batch
MiniBatch = 1

# maximal iteration number
Iterations = 20

# primary learning rate 
# learning rate would be decayed after every iteration
# the range is 0~1
LearningRate = 0.01

# decay rate of learning rate
# the range is 0~1
RateDecay = 0.01

# the threshold of rmse for iteration stoping
# the range is 0~1
Epsilon = 0.1


